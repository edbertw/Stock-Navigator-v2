{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: bs4 in ./venv/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.12/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.41)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.12)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.12/site-packages (from faiss-cpu) (2.2.3)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./venv/lib/python3.12/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.12/site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain faiss-cpu transformers bs4 -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-scraping information and writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T06:34:09.240357Z",
     "iopub.status.busy": "2025-02-28T06:34:09.240038Z",
     "iopub.status.idle": "2025-02-28T06:34:09.446593Z",
     "shell.execute_reply": "2025-02-28T06:34:09.445912Z",
     "shell.execute_reply.started": "2025-02-28T06:34:09.240333Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://smartasset.com/investing/stock-correlation\"\n",
    "\n",
    "r = requests.get(URL)\n",
    "#print(r.content)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "paragraphs = soup.find_all('p')\n",
    "paragraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n",
    "\n",
    "filename = \"corr.txt\"\n",
    "with open(f\"/kaggle/input/knowledge_base/{filename}\", 'w', encoding = 'utf-8') as file:\n",
    "  for paragraph in paragraph_texts:\n",
    "    file.write(paragraph + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:39:17.527969Z",
     "iopub.status.busy": "2025-02-28T07:39:17.527703Z",
     "iopub.status.idle": "2025-02-28T07:39:17.786126Z",
     "shell.execute_reply": "2025-02-28T07:39:17.785288Z",
     "shell.execute_reply.started": "2025-02-28T07:39:17.527948Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL =\"https://smartasset.com/investing/stock-correlation\"\n",
    "\n",
    "r = requests.get(URL)\n",
    "#print(r.content)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "paragraphs = soup.find_all('p')\n",
    "paragraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n",
    "\n",
    "filename = \"corr.txt\"\n",
    "with open(f\"/kaggle/working/{filename}\", 'w', encoding = 'utf-8') as file:\n",
    "  for paragraph in paragraph_texts:\n",
    "    file.write(paragraph + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL =input(\"Enter URL to scrape: \")\n",
    "\n",
    "r = requests.get(URL)\n",
    "print(r.content)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "paragraphs = soup.find_all('p')\n",
    "paragraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n",
    "\n",
    "filename = input(\"Enter relevant file name: \")\n",
    "with open(f\"/content/{filename}\", 'a', encoding = 'utf-8') as file:\n",
    "  for paragraph in paragraph_texts:\n",
    "    file.write(paragraph + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[1;32m      4\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKnowledge_Base/candlestick.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKnowledge_Base/ma.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKnowledge_Base/macd.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_paths = [\n",
    "    \"Knowledge_Base/candlestick.txt\",\n",
    "    \"Knowledge_Base/ma.txt\",\n",
    "    \"Knowledge_Base/momentum.txt\",\n",
    "    \"Knowledge_Base/rsi.txt\",\n",
    "    \"Knowledge_Base/bollinger.txt\",\n",
    "    \"Knowledge_Base/corr.txt\",\n",
    "    \"Knowledge_Base/cumul.txt\",\n",
    "    \"Knowledge_Base/macd.txt\"\n",
    "]\n",
    "\n",
    "documents = []\n",
    "for file_path in file_paths:\n",
    "    loader = TextLoader(file_path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:55:56.408530Z",
     "iopub.status.busy": "2025-02-28T07:55:56.408182Z",
     "iopub.status.idle": "2025-02-28T07:55:57.382834Z",
     "shell.execute_reply": "2025-02-28T07:55:57.382014Z",
     "shell.execute_reply.started": "2025-02-28T07:55:56.408503Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Use sentence-transformers for generating embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:56:04.540865Z",
     "iopub.status.busy": "2025-02-28T07:56:04.540575Z",
     "iopub.status.idle": "2025-02-28T07:56:04.872541Z",
     "shell.execute_reply": "2025-02-28T07:56:04.871645Z",
     "shell.execute_reply.started": "2025-02-28T07:56:04.540843Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Use a FAISS vector database to store document embeddings\n",
    "vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:57:13.097031Z",
     "iopub.status.busy": "2025-02-28T07:57:13.096733Z",
     "iopub.status.idle": "2025-02-28T07:57:13.102441Z",
     "shell.execute_reply": "2025-02-28T07:57:13.101582Z",
     "shell.execute_reply.started": "2025-02-28T07:57:13.097009Z"
    }
   },
   "outputs": [],
   "source": [
    "class QAPipelineWrapper:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.task = \"question-answering\"\n",
    "\n",
    "    def __call__(self, prompt, **kwargs):\n",
    "        # Format the input for the QA pipeline\n",
    "        question = kwargs.get(\"question\", \"What is Momentum?\")  # Default question if not provided\n",
    "        context = prompt  # The prompt contains the context\n",
    "        # Clean the context to remove any special characters or formatting\n",
    "        context = self._clean_text(context[0])\n",
    "        \n",
    "        # Format the input for the QA pipeline\n",
    "        inputs = {\n",
    "            \"question\": question,\n",
    "            \"context\": context\n",
    "        }\n",
    "        return self.pipeline(inputs)[\"answer\"]\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        text = \"\".join(char for char in text if ord(char) < 128)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:06:57.196177Z",
     "iopub.status.busy": "2025-02-28T08:06:57.195856Z",
     "iopub.status.idle": "2025-02-28T08:07:14.919853Z",
     "shell.execute_reply": "2025-02-28T08:07:14.918965Z",
     "shell.execute_reply.started": "2025-02-28T08:06:57.196148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Can you explain momentum in absolute detail?\n",
      "A: Momentum investing is primarily a short-term strategy. It focuses on identifying stocks that are currently trending upward and buying them with the expectation that the trend will continue in the short term. As soon as the momentum starts to fade or reverse, the investor sells the stock to capture the short-term gains. To calculate a stock's momentum, you can use the following formula: Momentum = Current Price / Price X months ago\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "model_name = \"google/flan-t5-large\"  # You can choose other models\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set up the pipeline\n",
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,  # Max token length for output\n",
    "    num_beams=5,     # Beam search for better answers, change from 3\n",
    "    temperature = 0.5,\n",
    "    do_sample = True,\n",
    "    top_p = 0.9 #nucleus sampling\n",
    ")\n",
    "\n",
    "# Wrap the pipeline for LangChain\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Use your retriever (assuming `vectorstore` is already defined)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "rag_pipeline = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",  # \"map_reduce\", \"refine\", \"map_rerank\", etc.\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "question = \"Can you explain momentum in absolute detail?\"\n",
    "response = rag_pipeline.run(question)\n",
    "print(f\"Q: {question}\\nA: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:11:06.801018Z",
     "iopub.status.busy": "2025-02-28T08:11:06.800715Z",
     "iopub.status.idle": "2025-02-28T08:11:12.655602Z",
     "shell.execute_reply": "2025-02-28T08:11:12.654472Z",
     "shell.execute_reply.started": "2025-02-28T08:11:06.800997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore saved successfully!\n",
      "Generative model and tokenizer saved successfully!\n",
      "RAG pipeline configuration saved successfully!\n"
     ]
    }
   ],
   "source": [
    "vectorstore.save_local(\"/kaggle/working/retriever_data/\")\n",
    "print(\"Vectorstore saved successfully!\")\n",
    "\n",
    "\n",
    "save_directory = \"/kaggle/working/generative_model\"\n",
    "pipeline = llm.pipeline \n",
    "\n",
    "pipeline.model.save_pretrained(save_directory)\n",
    "pipeline.tokenizer.save_pretrained(save_directory)\n",
    "print(\"Generative model and tokenizer saved successfully!\")\n",
    "\n",
    "import json\n",
    "\n",
    "# Save the configuration of the RAG pipeline\n",
    "rag_config = {\n",
    "    \"chain_type\": \"stuff\",\n",
    "    \"retriever_path\": \"/kaggle/working/retriever_data\", \n",
    "    \"model_path\": \"/kaggle/working/generative_model\",  \n",
    "    \"tokenizer_path\": \"/kaggle/working/generative_model\"  \n",
    "}\n",
    "\n",
    "\n",
    "with open(\"/kaggle/working/rag_config.json\", \"w\") as f:\n",
    "    json.dump(rag_config, f)\n",
    "\n",
    "print(\"RAG pipeline configuration saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T08:07:30.026494Z",
     "iopub.status.busy": "2025-02-28T08:07:30.026158Z",
     "iopub.status.idle": "2025-02-28T08:07:44.534402Z",
     "shell.execute_reply": "2025-02-28T08:07:44.533646Z",
     "shell.execute_reply.started": "2025-02-28T08:07:30.026468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is MACD ?\n",
      "A: MACD full form: Moving Average Convergence Divergence and is one of the most widely used momentum indicators in technical analysis. Gerald Appel was the creator of this indicator at the end of the 1970s. By computing the distinction between two time period intervals, which are a compilation of historical time series, this indicator is used to define momentum and its directional resilience. MACD uses moving averages of two distinct time intervals (most commonly historical closing prices of ------------\n"
     ]
    }
   ],
   "source": [
    "question = \"What is MACD ?\"\n",
    "response = rag_pipeline.run(question)\n",
    "print(f\"Q: {question}\\nA: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load the RAG configuration\n",
    "with open(\"/kaggle/working/rag_config.json\", \"r\") as f:\n",
    "    rag_config = json.load(f)\n",
    "\n",
    "# Load the vector store\n",
    "vectorstore = FAISS.load_local(rag_config[\"retriever_path\"])\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(rag_config[\"model_path\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(rag_config[\"tokenizer_path\"])\n",
    "\n",
    "# Create the QA pipeline\n",
    "hf_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Wrap it in LangChain's HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Recreate the RAG pipeline\n",
    "rag_pipeline = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=rag_config[\"chain_type\"],  # Use the saved chain type\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "response = rag_pipeline.run(\"What is Momentum?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6758116,
     "sourceId": 10876902,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6758909,
     "sourceId": 10878089,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
