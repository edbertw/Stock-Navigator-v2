{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10876902,"sourceType":"datasetVersion","datasetId":6758116},{"sourceId":10878089,"sourceType":"datasetVersion","datasetId":6758909}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain faiss-cpu transformers bs4 -U langchain-community torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:41:20.196665Z","iopub.execute_input":"2025-02-28T05:41:20.196946Z","iopub.status.idle":"2025-02-28T05:41:40.003457Z","shell.execute_reply.started":"2025-02-28T05:41:20.196924Z","shell.execute_reply":"2025-02-28T05:41:40.002365Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain\n  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bs4\n  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\nCollecting langchain-community\n  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\nDownloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\nDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, async-timeout, bs4, pydantic-settings, langchain-core, langchain-text-splitters, langchain, transformers, langchain-community, faiss-cpu\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 bs4-0.0.2 faiss-cpu-1.10.0 httpx-sse-0.4.0 langchain-0.3.19 langchain-community-0.3.18 langchain-core-0.3.40 langchain-text-splitters-0.3.6 pydantic-settings-2.8.1 python-dotenv-1.0.1 transformers-4.49.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Web-scraping information and writing to file","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n\nURL = \"https://smartasset.com/investing/stock-correlation\"\n\nr = requests.get(URL)\n#print(r.content)\n\nsoup = BeautifulSoup(r.text, 'html.parser')\nparagraphs = soup.find_all('p')\nparagraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n\nfilename = \"corr.txt\"\nwith open(f\"/kaggle/input/knowledge_base/{filename}\", 'w', encoding = 'utf-8') as file:\n  for paragraph in paragraph_texts:\n    file.write(paragraph + \"\\n\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T06:34:09.240038Z","iopub.execute_input":"2025-02-28T06:34:09.240357Z","iopub.status.idle":"2025-02-28T06:34:09.446593Z","shell.execute_reply.started":"2025-02-28T06:34:09.240333Z","shell.execute_reply":"2025-02-28T06:34:09.445912Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"## For Kaggle","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n\nURL =\"https://smartasset.com/investing/stock-correlation\"\n\nr = requests.get(URL)\n#print(r.content)\n\nsoup = BeautifulSoup(r.text, 'html.parser')\nparagraphs = soup.find_all('p')\nparagraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n\nfilename = \"corr.txt\"\nwith open(f\"/kaggle/working/{filename}\", 'w', encoding = 'utf-8') as file:\n  for paragraph in paragraph_texts:\n    file.write(paragraph + \"\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:39:17.527703Z","iopub.execute_input":"2025-02-28T07:39:17.527969Z","iopub.status.idle":"2025-02-28T07:39:17.786126Z","shell.execute_reply.started":"2025-02-28T07:39:17.527948Z","shell.execute_reply":"2025-02-28T07:39:17.785288Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"## Appending to file","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\n\nURL =input(\"Enter URL to scrape: \")\n\nr = requests.get(URL)\nprint(r.content)\n\nsoup = BeautifulSoup(r.text, 'html.parser')\nparagraphs = soup.find_all('p')\nparagraph_texts = [p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)]\n\nfilename = input(\"Enter relevant file name: \")\nwith open(f\"/content/{filename}\", 'a', encoding = 'utf-8') as file:\n  for paragraph in paragraph_texts:\n    file.write(paragraph + \"\\n\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nfile_paths = [\n    \"/kaggle/input/knowledge-base-2/candlestick.txt\",\n    \"/kaggle/input/knowledge-base-2/ma.txt\",\n    \"/kaggle/input/knowledge-base-2/momentum.txt\",\n    \"/kaggle/input/knowledge-base-2/rsi.txt\",\n    \"/kaggle/input/knowledge-base-2/bollinger.txt\",\n    \"/kaggle/input/knowledge-base-2/corr.txt\",\n    \"/kaggle/input/knowledge-base-2/cumul.txt\",\n    \"/kaggle/input/knowledge-base-2/macd.txt\"\n]\n\ndocuments = []\nfor file_path in file_paths:\n    loader = TextLoader(file_path)\n    documents.extend(loader.load())\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\nchunks = text_splitter.split_documents(documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:55:52.783401Z","iopub.execute_input":"2025-02-28T07:55:52.783711Z","iopub.status.idle":"2025-02-28T07:55:52.831463Z","shell.execute_reply.started":"2025-02-28T07:55:52.783688Z","shell.execute_reply":"2025-02-28T07:55:52.830763Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\n\n# Use sentence-transformers for generating embeddings\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nembeddings = embedding_model.embed_documents([chunk.page_content for chunk in chunks])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:55:56.408182Z","iopub.execute_input":"2025-02-28T07:55:56.408530Z","iopub.status.idle":"2025-02-28T07:55:57.382834Z","shell.execute_reply.started":"2025-02-28T07:55:56.408503Z","shell.execute_reply":"2025-02-28T07:55:57.382014Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"from langchain.vectorstores import FAISS\n\n# Use a FAISS vector database to store document embeddings\nvectorstore = FAISS.from_documents(documents=chunks, embedding=embedding_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:56:04.540575Z","iopub.execute_input":"2025-02-28T07:56:04.540865Z","iopub.status.idle":"2025-02-28T07:56:04.872541Z","shell.execute_reply.started":"2025-02-28T07:56:04.540843Z","shell.execute_reply":"2025-02-28T07:56:04.871645Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"class QAPipelineWrapper:\n    def __init__(self, pipeline):\n        self.pipeline = pipeline\n        self.task = \"question-answering\"\n\n    def __call__(self, prompt, **kwargs):\n        # Format the input for the QA pipeline\n        question = kwargs.get(\"question\", \"What is Momentum?\")  # Default question if not provided\n        context = prompt  # The prompt contains the context\n        # Clean the context to remove any special characters or formatting\n        context = self._clean_text(context[0])\n        \n        # Format the input for the QA pipeline\n        inputs = {\n            \"question\": question,\n            \"context\": context\n        }\n        return self.pipeline(inputs)[\"answer\"]\n\n    def _clean_text(self, text):\n        text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n        text = \"\".join(char for char in text if ord(char) < 128)\n        return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T07:57:13.096733Z","iopub.execute_input":"2025-02-28T07:57:13.097031Z","iopub.status.idle":"2025-02-28T07:57:13.102441Z","shell.execute_reply.started":"2025-02-28T07:57:13.097009Z","shell.execute_reply":"2025-02-28T07:57:13.101582Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.chains import RetrievalQA\n\n\nmodel_name = \"google/flan-t5-large\"  # You can choose other models\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set up the pipeline\nhf_pipeline = pipeline(\n    \"text2text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=512,  # Max token length for output\n    num_beams=5,     # Beam search for better answers, change from 3\n    temperature = 0.5,\n    do_sample = True,\n    top_p = 0.9 #nucleus sampling\n)\n\n# Wrap the pipeline for LangChain\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\n# Use your retriever (assuming `vectorstore` is already defined)\nretriever = vectorstore.as_retriever()\n\n# Create a RetrievalQA chain\nrag_pipeline = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"refine\",  # \"map_reduce\", \"refine\", \"map_rerank\", etc.\n    retriever=retriever\n)\n\nquestion = \"Can you explain momentum in absolute detail?\"\nresponse = rag_pipeline.run(question)\nprint(f\"Q: {question}\\nA: {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:06:57.195856Z","iopub.execute_input":"2025-02-28T08:06:57.196177Z","iopub.status.idle":"2025-02-28T08:07:14.919853Z","shell.execute_reply.started":"2025-02-28T08:06:57.196148Z","shell.execute_reply":"2025-02-28T08:07:14.918965Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Q: Can you explain momentum in absolute detail?\nA: Momentum investing is primarily a short-term strategy. It focuses on identifying stocks that are currently trending upward and buying them with the expectation that the trend will continue in the short term. As soon as the momentum starts to fade or reverse, the investor sells the stock to capture the short-term gains. To calculate a stock's momentum, you can use the following formula: Momentum = Current Price / Price X months ago\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"vectorstore.save_local(\"/kaggle/working/retriever_data/\")\nprint(\"Vectorstore saved successfully!\")\n\n\nsave_directory = \"/kaggle/working/generative_model\"\npipeline = llm.pipeline \n\npipeline.model.save_pretrained(save_directory)\npipeline.tokenizer.save_pretrained(save_directory)\nprint(\"Generative model and tokenizer saved successfully!\")\n\nimport json\n\n# Save the configuration of the RAG pipeline\nrag_config = {\n    \"chain_type\": \"stuff\",\n    \"retriever_path\": \"/kaggle/working/retriever_data\", \n    \"model_path\": \"/kaggle/working/generative_model\",  \n    \"tokenizer_path\": \"/kaggle/working/generative_model\"  \n}\n\n\nwith open(\"/kaggle/working/rag_config.json\", \"w\") as f:\n    json.dump(rag_config, f)\n\nprint(\"RAG pipeline configuration saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T08:11:06.800715Z","iopub.execute_input":"2025-02-28T08:11:06.801018Z","iopub.status.idle":"2025-02-28T08:11:12.655602Z","shell.execute_reply.started":"2025-02-28T08:11:06.800997Z","shell.execute_reply":"2025-02-28T08:11:12.654472Z"}},"outputs":[{"name":"stdout","text":"Vectorstore saved successfully!\nGenerative model and tokenizer saved successfully!\nRAG pipeline configuration saved successfully!\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"question = \"What is correlation?\"\nresponse = rag_pipeline.run(question)\nprint(f\"Q: {question}\\nA: {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:09:05.328724Z","iopub.execute_input":"2025-02-28T09:09:05.329027Z","iopub.status.idle":"2025-02-28T09:09:21.690714Z","shell.execute_reply.started":"2025-02-28T09:09:05.329003Z","shell.execute_reply":"2025-02-28T09:09:21.689968Z"}},"outputs":[{"name":"stdout","text":"Q: What is correlation?\nA: The key to correlation trading is being able to predict when future realized correlation amongst the stocks of a particular index will be greater or less than the \"implied\" correlation level derived from derivatives on the index and its single stocks. One observation related to correlation trading is the principle ofdiversification, which implies that the volatility of a portfolio of securities is less than (or equal to) the average volatility of all the securities in that portfolio (This has nothing to do withModern Portfolio Theoryand follows from Statistics 101, definition of portfolio variance). The lower the correlation amongst the individual securities, the lower the overallvolatilityof the entire portfolio. This is due totheway in which variances behave when summing correlated random variables.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"import json\nfrom langchain.chains import RetrievalQA\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.vectorstores import FAISS\n\n# Load the RAG configuration\nwith open(\"/kaggle/working/rag_config.json\", \"r\") as f:\n    rag_config = json.load(f)\n\n# Load the vector store\nvectorstore = FAISS.load_local(rag_config[\"retriever_path\"])\n\n# Load the model and tokenizer\nmodel = AutoModelForQuestionAnswering.from_pretrained(rag_config[\"model_path\"])\ntokenizer = AutoTokenizer.from_pretrained(rag_config[\"tokenizer_path\"])\n\n# Create the QA pipeline\nhf_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n\n# Wrap it in LangChain's HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\n# Initialize the retriever\nretriever = vectorstore.as_retriever()\n\n# Recreate the RAG pipeline\nrag_pipeline = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=rag_config[\"chain_type\"],  # Use the saved chain type\n    retriever=retriever\n)\n\n# Ask a question\nresponse = rag_pipeline.run(\"What is Momentum?\")\nprint(response)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}